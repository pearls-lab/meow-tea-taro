# Copyright 2024 Bytedance Ltd. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
SFT dataset
- We assume user pass a single parquet file.
- We load all the data into the memory.
Each parquet file contains
"""

from typing import Union, Optional

import pandas as pd
import re
import torch
from omegaconf.listconfig import ListConfig
from torch.utils.data import Dataset
from transformers import PreTrainedTokenizer, ProcessorMixin


import verl.utils.torch_functional as verl_F
from verl.utils import hf_tokenizer
from verl.utils.fs import copy_to_local
from verl.utils.model import compute_position_id_with_mask


class ChatBasedSFTDataset(Dataset):
    """
    This is an in-memory SFTDataset

    Arguments:
        config (OmegaConf): the data config
    """

    def __init__(
        self, 
        parquet_files: Union[str, ListConfig],
        tokenizer,
        config,
        processor: Optional[ProcessorMixin] = None,
    ):
        config = config or {}
        self.truncation = config.get("truncation", "error")
        self.max_length = config.get("max_length", 1024)
        self.use_shm = config.get("use_shm", False)

        # Get messages_key from the new multiturn config structure
        chat_based_config = config.get("chat_based", {})
        self.messages_key = chat_based_config.get("messages_key", "messages")

        self.image_key = chat_based_config.get("image_key", "images")
        self.video_key = chat_based_config.get("video_key", "videos")
        self.apply_chat_template_kwargs = chat_based_config.get("apply_chat_template_kwargs", {})
        self.return_multi_modal_inputs = chat_based_config.get("return_multi_modal_inputs", True)

        assert self.truncation in ["error", "left", "right"]

        if not isinstance(parquet_files, ListConfig):
            parquet_files = [parquet_files]

        self.parquet_files = parquet_files
        if isinstance(tokenizer, str):
            tokenizer = hf_tokenizer(tokenizer)
        self.tokenizer: PreTrainedTokenizer = tokenizer
        self.processor = processor

        self._download()
        self._read_files_and_process()

    def _download(self):
        for i, parquet_file in enumerate(self.parquet_files):
            self.parquet_files[i] = copy_to_local(parquet_file, verbose=True, use_shm=self.use_shm)

    def _read_files_and_process(self):
        def series_to_item(ls):
            if isinstance(ls, list):
                return ls
            return ls[0]

        dataframes = []
        for parquet_file in self.parquet_files:
            df = pd.read_parquet(parquet_file)
            dataframes.append(df)
        self.dataframe = pd.concat(dataframes)

        # Extract messages list from dataframe
        self.messages = self.dataframe[self.messages_key].apply(series_to_item).tolist()
        self.dataframe_dict = self.dataframe.to_dict(orient="records")

    def _truncate_system_template(self, text: str) -> str:
        """
        Given string generated by chat template, truncate the system prompt block.
        Example:
            <im_start>system ... <im_end><im_start>user ... <im_end><im_start>assistant
            becomes ->
            <im_start>user ... <im_end><im_start>assistant
        """
        pattern = r'<\|im_start\|>system\n.*?<\|im_end\|>\n'
        return re.sub(pattern, '', text, flags=re.DOTALL)

    def _build_messages(self, example: dict):
        messages: list = example[self.messages_key]

        if self.image_key in example or self.video_key in example:
            for message in messages:
                content = message["content"]
                if not isinstance(content, str):
                    continue
                content_list = []
                segments = re.split("(<image>|<video>)", content)
                segments = [item for item in segments if item != ""]
                for segment in segments:
                    if segment == "<image>":
                        content_list.append({"type": "image"})
                    elif segment == "<video>":
                        content_list.append({"type": "video"})
                    else:
                        content_list.append({"type": "text", "text": segment})

                message["content"] = content_list

        return messages
    
    def __len__(self):
        return len(self.messages)

    def __getitem__(self, item):
        row_dict = self.dataframe_dict[item].copy()
        messages = self._build_messages(row_dict)
        model_inputs = {}

        if self.processor:
            from verl.utils.dataset.vision_utils import process_image, process_video

            raw_text = self.processor.apply_chat_template(
                messages, add_generation_prompt=False, tokenize=False, **self.apply_chat_template_kwargs
            )
            multi_modal_data = {}

            images = None
            row_dict_images = row_dict.pop(self.image_key, None)
            if row_dict_images:
                images = [process_image(image) for image in row_dict_images]
                multi_modal_data["image"] = images

            videos = None
            row_dict_videos = row_dict.pop(self.video_key, None)
            if row_dict_videos:
                videos = [process_video(video) for video in row_dict_videos]
                multi_modal_data["video"] = [video.numpy() for video in videos]

            model_inputs = self.processor(text=[raw_text], images=images, videos=videos, return_tensors="pt")
            input_ids = model_inputs.pop("input_ids")
            attention_mask = model_inputs.pop("attention_mask")

            if self.return_multi_modal_inputs:
                row_dict["multi_modal_inputs"] = dict(model_inputs)
        else:
            raw_text = self.tokenizer.apply_chat_template(
                messages, add_generation_prompt=False, tokenize=False, **self.apply_chat_template_kwargs
            )
            model_inputs = self.tokenizer(raw_text, return_tensors="pt", add_special_tokens=False)
            input_ids = model_inputs.pop("input_ids")
            attention_mask = model_inputs.pop("attention_mask")

        prompt_chat = messages[:-1]
        if self.processor:
            prompt_chat_str = self.processor.apply_chat_template(
                prompt_chat, add_generation_prompt=True, tokenize=False
            )
            prompt_model_inputs = self.processor(text=prompt_chat_str, add_special_tokens=False, return_tensors="pt")
            prompt_ids = prompt_model_inputs["input_ids"][0]
        else:
            prompt_chat_str = self.tokenizer.apply_chat_template(
                prompt_chat, add_generation_prompt=True, tokenize=False
            )
            prompt_ids = self.tokenizer.encode(prompt_chat_str, add_special_tokens=False)
        prompt_length = len(prompt_ids)

        input_ids, attention_mask = verl_F.postprocess_data(
            input_ids=input_ids,
            attention_mask=attention_mask,
            max_length=self.max_length,
            pad_token_id=self.tokenizer.pad_token_id,
            left_pad=False,
            truncation=self.truncation,
        )
        input_ids = input_ids[0]
        attention_mask = attention_mask[0]

        position_ids = compute_position_id_with_mask(attention_mask.unsqueeze(0))[0]

        loss_mask = attention_mask.clone()
        if prompt_length > 0:
            loss_mask[:prompt_length] = 0

        # mask out padding tokens
        loss_mask[input_ids == self.tokenizer.pad_token_id] = 0

        # mask out the last token which is eos
        if attention_mask.sum() > 0:
            last_token_idx = attention_mask.sum() - 1
            loss_mask[last_token_idx] = 0

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "position_ids": position_ids,
            "loss_mask": loss_mask,
        }